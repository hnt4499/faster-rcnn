data:
    train:
        format: VOCDataset
        info_path:
            - /home/jupyter/Documents/projects/faster-rcnn/data/exp_1_five_folds/voc2007_trainval_0.csv
            - /home/jupyter/Documents/projects/faster-rcnn/data/exp_1_five_folds/voc2007_trainval_1.csv
            - /home/jupyter/Documents/projects/faster-rcnn/data/exp_1_five_folds/voc2007_trainval_2.csv
            - /home/jupyter/Documents/projects/faster-rcnn/data/exp_1_five_folds/voc2007_trainval_3.csv
        difficult: false
    val:
        format: VOCDataset
        info_path:
            - /home/jupyter/Documents/projects/faster-rcnn/data/exp_1_five_folds/voc2007_trainval_4.csv
        difficult: false
    test:
        format: VOCDataset
        info_path:
            - /home/jupyter/Documents/projects/faster-rcnn/data/orig/voc2007_test.csv
        difficult: false

model:
    backbone:
        model_name: resnet50
        freeze_all: false
    anchor_areas:
        # - 16384  # 128 * 128
        # - 65536  # 256 * 256
        # - 262144  # 512 * 512
        - 9216  # 96 * 96
        - 36864  # 192 * 192
        - 147456  # 384 * 384
    aspect_ratios:
        - 0.5
        - 1.0
        - 2.0
    kernel_size: 3
    num_channels: 512
    sampler:
        # sampler_name: RandomSamplerWithHardNegativeMining
        # kwargs:
        #     positive_fraction: 0.5
        #     batch_size_per_image: 64  # don't set this too large, as negative samples will likely dominate positive samples.
        #     hard_fraction: {start: 0, end: 0.5, steps: 1000, dtype: float}
        sampler_name: RandomSampler
        kwargs:
            positive_fraction: 0.5
            batch_size_per_image: 64  # don't set this too large, as negative samples will likely dominate positive samples.
    reg_lambda: 1.0
    normalize_offsets: false
    handle_cross_boundary_boxes:  # note that the behavior during training and testing is different
        during_training: false
        during_testing: true

training:
    # work_dir: /home/jupyter/Documents/projects/faster-rcnn/work_dirs/  # set to `null` to not save anything
    work_dir: null  # set to `null` to not save anything
    input_size: 400  # the `anchor_areas` and `input_size` are directly dependent of each other
    transforms_mode: simple  # refer to `faster_rcnn.transforms.get_transforms`
    device: cuda
    learning_rate: 0.0001
    batch_size: 16
    num_epochs: 1000
    num_workers: 1
    testing: false  # set to 'true' to perform only 10 iterations per epoch
    metrics:
        rpn:
            BoxRecall: {iou_threshold: 0.5}
            MeanAverageBestOverlap: {}
            DRWinCurve: {iou_threshold: 0.5}

evaluating:
    input_size: 400
    transforms_mode: simple
    post_process:
        rpn:  # RPN hyperparameters
            matcher:  # matches anchor boxes with groundtruth boxes
                high_threshold: 0.7
                low_threshold: 0.3
                allow_low_quality_matches: true
            pre_nms_top_n: 2000  # number of boxes to keep before NMS
            post_nms_top_n: 500  # number of boxes to keep after NMS
            nms_iou_threshold: 0.7  # IOU threshold during NMS
            score_threshold: 0.1  # boxes with objectness score smaller than this will be removed
            min_scale: 0.01  # fraction of box width/height to image width/height
